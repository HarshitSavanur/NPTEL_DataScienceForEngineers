# Set the random seed for reproducibility
set.seed(123)
# Load the required libraries
library(ggplot2)
library(MASS)
# Generate random data with two circular clusters
n <- 150  # Total number of data points
centers <- 3  # Number of clusters
radius <- 0.6  # Radius of clusters
# Create random cluster centers in a circular pattern
theta <- seq(0, 2 * pi, length.out = centers + 1)[-1]  # Angle in radians
cluster_centers <- cbind(cos(theta) * radius, sin(theta) * radius)
# Generate data points around circular cluster centers
data_points <- matrix(0, n, 2)
for (i in 1:centers) {
start <- 1 + (i - 1) * (n / centers)
end <- i * (n / centers)
data_points[start:end, ] <- mvrnorm(end - start + 1, mu = cluster_centers[i, ], Sigma = diag(2) * 0.01)
}
# plot the data points before clustering
ggplot(data = as.data.frame(data_points), aes(x = data_points[, 1], y = data_points[, 2])) +
geom_point(size = 3) +
labs(title = "Data Points (Three Circular Clusters)", x = "X-axis", y = "Y-axis")
# Perform K-means clustering
kmeans_result <- kmeans(data_points,3,15)
#?kmeans
print(kmeans_result)
# Extract cluster assignments
cluster_assignments <- kmeans_result$cluster
# Create a data frame for plotting
df <- data.frame(x = data_points[, 1], y = data_points[, 2], Cluster = as.factor(cluster_assignments))
# Plot the data points with cluster assignments
ggplot(df, aes(x, y, color = Cluster)) +
geom_point(size = 3) +
labs(title = "K-means Clustering (Three Circular Clusters)", x = "X-axis", y = "Y-axis") +
scale_color_manual(values = c("red", "blue", "green"))  # Customize cluster colors as needed
# Perform K-means clustering
kmeans_result <- kmeans(data_points,3,15)
#?kmeans
print(kmeans_result)
# Extract cluster assignments
cluster_assignments <- kmeans_result$cluster
# Create a data frame for plotting
df <- data.frame(x = data_points[, 1], y = data_points[, 2], Cluster = as.factor(cluster_assignments))
# Plot the data points with cluster assignments
ggplot(df, aes(x, y, color = Cluster)) +
geom_point(size = 3) +
labs(title = "K-means Clustering (Three Circular Clusters)", x = "X-axis", y = "Y-axis") +
scale_color_manual(values = c("red", "blue", "green"))  # Customize cluster colors as needed
for (i in 1:centers) {
start <- 1 + (i - 1) * (n / centers)
end <- i * (n / centers)
data_points[start:end, ] <- mvrnorm(end - start + 1, mu = cluster_centers[i, ], Sigma = diag(2) * 0.01)
}
# plot the data points before clustering
ggplot(data = as.data.frame(data_points), aes(x = data_points[, 1], y = data_points[, 2])) +
geom_point(size = 3) +
labs(title = "Data Points (Three Circular Clusters)", x = "X-axis", y = "Y-axis")
# Perform K-means clustering
kmeans_result <- kmeans(data_points,3,15)
#?kmeans
print(kmeans_result)
# Extract cluster assignments
cluster_assignments <- kmeans_result$cluster
# Create a data frame for plotting
df <- data.frame(x = data_points[, 1], y = data_points[, 2], Cluster = as.factor(cluster_assignments))
# Plot the data points with cluster assignments
ggplot(df, aes(x, y, color = Cluster)) +
geom_point(size = 3) +
labs(title = "K-means Clustering (Three Circular Clusters)", x = "X-axis", y = "Y-axis") +
scale_color_manual(values = c("red", "blue", "green"))  # Customize cluster colors as needed
# In R we will try Problem 1
# Let's define the probability of drawing a green ball
P_A = 3/8
# Let's define the probability of drawing a green ball given that the first ball is green
P_B_given_A = 2/7
# Let's find the probability of drawing two green balls
P_A_and_B = P_A * P_B_given_A
P_A_and_B
# In R we will try Problem 1
# Let's define the probability of drawing a green ball
P_A = 3/8
# Let's define the probability of drawing a green ball given that the first ball is green
P_B_given_A = 2/7
# Let's find the probability of drawing two green balls
P_A_and_B = P_A * P_B_given_A
P_A_and_B
# Probability Distribution (visualizing the distribution)
# Discrete Random Variable: Number of Green Balls Drawn
# Let's plot the probability distribution of the number of green balls drawn
# Let's define the number of green balls drawn
green_balls = c(0, 1, 2)
# Probability Distribution (visualizing the distribution)
# Discrete Random Variable: Number of Green Balls Drawn
# Let's plot the probability distribution of the number of green balls drawn
# Let's define the number of green balls drawn
green_balls = c(0, 1, 2)
# Let's define the probability of drawing 0, 1, 2 green balls
prob_green_balls = c(5/28, 30/56, 3/28)
# Let's plot the probability distribution
barplot(prob_green_balls, names.arg = green_balls, xlab = "Number of Green Balls", ylab = "Probability", main = "Probability Distribution of Number of Green Balls Drawn")
# Continuous Random Variable: Height of Students
# Let's plot the probability distribution of the height of students
# Let's define the height of students
height = seq(140, 200, by = 1)
# Let's define the probability density function of the height of students
pdf_height = dnorm(height, mean = 170, sd = 10)
# Continuous Random Variable: Height of Students
# Let's plot the probability distribution of the height of students
# Let's define the height of students
height = seq(140, 200, by = 1)
# Let's define the probability density function of the height of students
pdf_height = dnorm(height, mean = 170, sd = 10)
# Let's plot the probability distribution
plot(height, pdf_height, type = "l", xlab = "Height", ylab = "Probability Density", main = "Probability Distribution of Height of Students")
# Binomial Mass Function
# Let's plot the binomial mass function
# Let's define the number of trials
n = 5
# Let's define the probability of success
p = 0.5
# Let's define the number of successes
k = 0:5
# Let's find the binomial mass function
binomial_mass = dbinom(k, size = n, prob = p)
binomial_mass
# Let's plot the binomial mass function
barplot(binomial_mass, names.arg = k, xlab = "Number of Successes", ylab = "Probability", main = "Binomial Mass Function")
# Gaussian or normal distribution
# Let's plot the Gaussian distribution
# Let's define the mean and standard deviation
mean = 0
sd = 1
# Let's define the range of x values
x = seq(-15, 15, by = 0.01)
# Let's find the Gaussian distribution
gaussian = dnorm(x, mean = mean, sd = sd)
gaussian
# Let's plot the Gaussian distribution
plot(x, gaussian, type = "l", xlab = "x", ylab = "Probability Density", main = "Gaussian Distribution")
#setwd("C:/Users/sharu/Desktop/PMRF_Lec new/NPTEL/NPTEL_TA_R/Data_Science_Engg_July23/Week8")
rm(list=ls())
#install.packages("caret",dependencies = TRUE)
#install.packages("class",dependencies = TRUE)
library(caret)
library(class)
#1. According to the built model, the within cluster sum of squares for each cluster is __ (the order of values in each option could be different):-
data = read.csv(file.choose(),header = T, row.names = "States")
fit<-kmeans(df,centers = 4, nstart=20)
# https://andrea-grianti.medium.com/kmeans-parameters-in-rstudio-explained-c493ec5a05df#:~:text=nstart%20represents%20the%20number%20of,t%20want%20to%20do%20manually.
print(fit$withinss)
#2. According to the built model, the size of each cluster is _______ (the order of values in each option could be different):-
print(fit$size)
#3. The Between Cluster Sum-of-Squares (BCSS) value of the built K-means model is ___________(Choose the appropriate range)
print(fit$betweenss)
#4. The Total Sum-of-Squares value of the built k-means model is________ (Choose the appropriate range)
print(fit$totss)
install.packages('datasets')
source("D:/Harshith/RVCE/Fourth Sem/NPTEL Data Science/NPTEL-Data-Science-for-Engineers-main/Google Drive Notes/Link 2/Week_8/Week8_decision.R", echo=TRUE)
